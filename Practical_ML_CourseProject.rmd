---
title: "Coursera Practical Machine Learning"
author: "Dianne Dino"
date: "August 7, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, tidy = TRUE)
```

### Overview
In this project, we are tasked to **predict the manner in which our correspondents did the exercise**. The data is gathered from [link](http://groupware.les.inf.puc-rio.br/har).

The **training data** for this project are available here:
[link](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv)
The **test data** are available here:
[link](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv)
### Set-up Data
```{r, echo = TRUE}
#Load libraries
library(data.table); library(caret);library(ggplot2); library(dplyr)
library(rpart);library(rpart.plot);library(RColorBrewer);library(rattle)
library(randomForest);library(party);library(rattle)
#Set-up Data
train <- fread("pml-training.csv")
test <- fread("pml-testing.csv")
train$V1 = NULL; test$V1 = NULL 
df = train
testing = test

dim(df);dim(testing)
```
### Data Exploration
Below is the count of classifiers in the dataset. (5 Levels) 
```{r, echo = TRUE, fig.width = 5, fig.height=5}
table(df$classe)
```
### Pre-Processing
```{r, echo = TRUE}
#Drop Columns with 50% and more Missing Data
pMiss <- function(x){return(sum(is.na(x))/length(x)*100)}
tmp = data.frame(apply(df,2,pMiss))
tmp = cbind(row.names(tmp),tmp)
colnames(tmp) = c('col_name','pcnt_missing_val')
row.names(tmp) = 1:nrow(tmp)
tmp = tmp[tmp$pcnt_missing_val>=50,1]
tmp = tmp %>% as.character()
#Train Set
df = select(df,-c(tmp)) #Dropped 100 columns
#Test Set
testing = select(testing, -(tmp)) #Dropped 100 columns
#Dropping columns you dont need
training  <- df[, -c(1:6)]
testing <- testing[,-c(1:6)]
dim(training); dim(testing)
```
### Modeling
#### Cross-Validation
Cross-Validation is done to ensure the accuracy and fitness of the model. 
```{r, echo = TRUE}
inTrain <- createDataPartition(y=training$classe, 
                               p=0.75, list = FALSE)
sub_train <- training[inTrain,]; sub_test <- training[-inTrain,]
dim(sub_train); dim(sub_test)
```
#### Modeling using Decision Trees
```{r, echo = TRUE}
#Fit to Model
modFitA1 <- rpart(classe ~ ., data=sub_train, method="class")
#Plot Tree
fancyRpartPlot(modFitA1)
#Predict
predictionsA1 <- predict(modFitA1, sub_test, type = "class")
#Metrics
confusionMatrix(predictionsA1, as.factor(sub_test$classe))$table
confusionMatrix(predictionsA1, as.factor(sub_test$classe))$overall[1]

```
#### Modeling using RF
```{r, echo = TRUE}
trControl <- trainControl(method="cv", number=5) #Set Folds
#Fit to Model
modFitB1 <- train(classe~., data=sub_train, method="rf", trControl=trControl, verbose=TRUE)
#Predict
predictionB1 <- predict(modFitB1, sub_test)
#Metrics
confusionMatrix(predictionB1, as.factor(sub_test$classe))$table
confusionMatrix(predictionB1, as.factor(sub_test$classe))$overall[1]

```
##### Plot RF Metrics
```{r, echo = TRUE}
#Plot RF Metrics
plot(modFitB1,main="Accuracy of Random forest model by number of predictors")
plot(modFitB1$finalModel,main="Model error of Random forest model by number of trees")
```
#### Varible Importance
After running the variable importance function, we've figured out that roll_belt is the most important variable in this model with the rest with only 75.5 value and below. 
```{r, echo = TRUE}
MostImpVars <- varImp(modFitB1)
MostImpVars
```
#### What Model to Use?
Random Model will be used in this project because of the stable and high metrics it posses.
#### Prediction Results using Test Set
```{r, echo =TRUE}
FinalTest <- predict(modFitB1,newdata=testing)
FinalTest
```